---
title: "Everyday Music Listening"
author: "John Ashley Burgoyne"
format:
  dashboard:
    orientation: columns
    theme: custom.scss
---

# Main Page

## {.sidebar}

**Research Focus**

Music is an integral part of everyday life and has the ability to evoke strong emotional responses, even when listeners do not understand the language of a song. While lyrics convey semantic meaning that may influence emotional interpretation, listeners often report similar emotional experiences when hearing cover versions in unfamiliar languages, suggesting that melody, rhythm, and vocal expression may play a more dominant role than lyrical comprehension.

This raises an important question about what truly shapes emotional responses to music: the meaning of the lyrics or the musical features themselves?

**Songs Analyzed**

- Solo - Clean Bandit (Original)
- Solo (Spanish Cover)
- Lost on You - LP (Original)
- Lost on You (Spanish Cover)
- Issues - Julia Michaels (Original)
- Issues (French Cover)

---

**Key Measures**

- Emotional Intensity (1-7)
- Valence (1-6)
- Familiarity (1-7)
- Lyric Comprehension (1-5)

## Column 1 {width=60%}

### {.tabset}

```{r}
#| title: Musical Elements
#| padding: 0px
knitr::include_graphics("selected_plots/07_stacked_bar_elements.png")
```

```{r}
#| title: Language Groups
#| padding: 0px
knitr::include_graphics("selected_plots/12_language_group_comparison.png")
```

## Column 2 {width=40%}

### Row 1 {height=30%}

**Key Finding**

Melody and vocal expression appear to dominate emotional responses regardless of lyric comprehension level.

### Row 2

```{r}
#| title: Emotional Response vs Valence by Song
#| padding: 0px
knitr::include_graphics("selected_plots/01_scatter_emotion_valence.png")
```

# The Participants

## {.sidebar}

**Demographics Overview**

**N = 39** completed responses

**Age Distribution**

- 87% aged 18-25
- Young adult sample

**Music Engagement**

- 80% daily listeners
- 54% have musical training

**Language Proficiency**

- 56% advanced English (C1-C2)
- 13% French B1+
- 10% Spanish B1+

---

**Language Groups**

- **English only**: B1+ English, no Spanish/French
- **English + French**: B1+ in both
- **English + Spanish**: B1+ in both

---

**Musical Training**

- 0 years (no formal training)
- 1-2 years
- 3-5 years
- 6+ years

---

**Age Ranges**

18-20, 21-25, 26-30, 31-40, 41+

## Column 1 {width=50%}

```{r}
#| title: Familiarity vs Comprehension
#| padding: 0px
knitr::include_graphics("selected_plots/02_scatter_familiar_comp.png")
```

## Column 2 {width=50%}

```{r}
#| title: Dual Group Comparison
#| padding: 0px
knitr::include_graphics("selected_plots/03_scatter_dual_group.png")
```

# Background

## {.sidebar}

**Research Question**

*To what extent do lyrics, compared to melody, influence emotional responses to music?*

---

**Hypothesis Test**

We use regression analysis to test whether lyric comprehension predicts emotional response:

- **If lyrics dominate**: Higher comprehension → stronger/more positive emotional response (significant positive slope)
- **If melody dominates**: Comprehension has little effect (flat slope, non-significant p-value)

## Column {width=100%}

### Study Overview

This study examines whether understanding song lyrics affects emotional responses to music. We collected data from 39 participants who listened to 6 songs (3 originals and 3 cover versions in different languages).

**Methodology**

Participants rated each song on:

- **Emotional Intensity** (1-7 scale): How strongly the music affected them
- **Valence** (1-6 scale): How positive/negative the emotional response was
- **Lyric Comprehension** (1-5 scale): How well they understood the lyrics

We then performed linear regression to determine if comprehension predicts emotional response.

# Analysis

## {.sidebar}

**Regression Analysis**

OLS regression testing whether lyric comprehension predicts emotional and cognitive outcomes.

---

**Models Tested**

- Emotional Response
- Valence
- Familiarity
- Memory

## Column 1 {width=50%}

### {.tabset}

```{r}
#| title: Comprehension → Emotion
#| padding: 0px
knitr::include_graphics("selected_plots/13_regression_comprehension_emotion.png")
```

```{r}
#| title: Comprehension → Valence
#| padding: 0px
knitr::include_graphics("selected_plots/14_regression_comprehension_valence.png")
```

```{r}
#| title: Stata Output
#| padding: 0px
knitr::include_graphics("selected_plots/stata_regression_familiarity.png")
```

## Column 2 {width=50%}

### Emotional Response & Valence

::: {style="overflow-y: auto; max-height: 80vh;"}

After estimating two linear regression models, we examined whether lyric comprehension predicts (a) emotional response strength and (b) emotional valence. In the first model, emotional response was regressed on comprehension. The coefficient for comprehension was positive (β = 0.10), but not statistically significant (p = 0.109). The model explained only 1.3% of the variance in emotional response (R² = 0.013), indicating a very weak relationship.

In the second model, valence was regressed on comprehension. Again, the coefficient was positive but extremely small (β = 0.02) and clearly non-significant (p = 0.719). The explanatory power of the model was negligible, with an R² of 0.001, suggesting that comprehension accounts for virtually none of the variation in emotional valence.

Taken together, these results provide no statistical evidence that understanding song lyrics meaningfully influences either the strength or the positivity of listeners' emotional responses. Although the estimated effects are in the expected positive direction, their magnitude is minimal and indistinguishable from zero. This suggests that emotional reactions to music in this sample are largely independent of lyric comprehension and may instead be driven by non-linguistic musical features such as melody, harmony, rhythm, or familiarity.

### Familiarity & Memory

In contrast to emotional response strength and valence, lyric comprehension significantly predicted both familiarity and memory. When familiarity was regressed on comprehension, the effect was positive and statistically significant (β = 0.26, p = 0.002). Higher comprehension was associated with greater perceived familiarity, although the model explained a modest proportion of variance (R² = 0.048). This suggests that understanding the lyrics contributes to familiarity, but is far from the sole determinant.

For memory, comprehension also emerged as a significant predictor, though in the opposite direction. Greater comprehension was associated with slightly lower memory scores (β = −0.05, p = 0.027). As with familiarity, the explanatory power of the model was limited (R² = 0.025), indicating that comprehension accounts for only a small fraction of variability in memory performance.

### Familiarity (Stata)

When familiarity was regressed on lyric comprehension, the results indicated a positive and statistically significant relationship (β = 0.26, p = 0.002). This suggests that participants who reported better understanding of the lyrics also tended to report higher familiarity with the song. However, the model explained only a modest portion of the variance in familiarity (R² = 0.048), indicating that while comprehension contributes to familiarity, it accounts for less than 5 percent of the variation.

These findings imply that understanding the lyrics slightly enhances perceived familiarity, but other factors, such as prior exposure to the song, musical structure, or general listening habits, likely play a much larger role in shaping how familiar a listener feels with a track.

### Conclusion

Taken together, these findings suggest a dissociation between emotional and cognitive outcomes. While lyric comprehension does not meaningfully influence the emotional strength or valence of listeners' responses, it does relate to more cognitively oriented judgments such as familiarity and memory. However, the small R² values indicate that these relationships are weak and that other factors, such as prior exposure, musical structure, repetition, or attentional engagement are more likely to play a much larger role.

:::

# Extras

## {.sidebar}

**Visualization Gallery**

Advanced chart types from the R Graph Gallery.

---

**Plot Types**

- **Ridgeline**: Distribution overlap across songs
- **Heatmap**: Song-level response patterns
- **Violin**: Group comparisons
- **Dumbbell**: Paired differences

## Column 1 {width=50%}

### {.tabset}

```{r}
#| title: Ridgeline
#| padding: 0px
knitr::include_graphics("visualizations/plots/advanced/01_ridgeline_emotion.png")
```

```{r}
#| title: Heatmap
#| padding: 0px
knitr::include_graphics("visualizations/plots/advanced/05_heatmap_songs.png")
```

## Column 2 {width=50%}

### {.tabset}

```{r}
#| title: Violin
#| padding: 0px
knitr::include_graphics("visualizations/plots/advanced/07_violin_basic.png")
```

```{r}
#| title: Dumbbell
#| padding: 0px
knitr::include_graphics("visualizations/plots/advanced/10_dumbbell.png")
```
